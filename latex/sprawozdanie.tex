
\documentclass{article}
\usepackage{polski} %może wymagac dokonfigurowania latexa, ale jest lepszy niż standardowy babel'owy [polish]
\usepackage[utf8]{inputenc}
\usepackage[OT4]{fontenc}
\usepackage{amsfonts}
\usepackage{graphicx,color} %include pdf's (and png's for raster graphics... avoid raster graphics!)
\usepackage{url}
\usepackage[pdftex,hyperfootnotes=false,pdfborder={0 0 0}]{hyperref} %za wszystkimi pakietami; pdfborder nie wszedzie tak samo zaimplementowane bo specyfikacja nieprecyzyjna; pod miktex'em po prostu nie widac wtedy ramek


\input{_ustawienia.tex}

\begin{document}

\input{_tytulowa}

\begin{abstract}
\emph{QAP} jest jednym z podstawowych problemów kombinatorycznych i jest on \emph{NP-trudny}. Stąd do jego rozwiązania stosuje się algorytmy heurystyczne, takie jak przeszukiwanie lokalne. W sprawozdaniu przedstawiamy porównanie dwóch najprostszych wersji Local Search: \emph{Greedy} i \emph{Steepest} oraz bardziej złożonych metaheurystyk: \emph{Tabu Search} i  \emph{Simulated Annealing}.
\end{abstract}


\section{Wstęp}
	\subsection{Opis problemu}
	\emph{\emph{QAP} (Quadratic Assignement Problem)} jest jednym z podstawowych problemów kombinatorycznych. Na instancję problemu składają się:
	\begin{itemize}
		\item{dwa równoliczne zbiory:
			\begin{itemize}
				\item{ $L$ (,,lokalizacje")}
				\item{ $W$ (,,wydziały") }
			\end{itemize}
			}
		\item{dwie macierze:
			\begin{itemize}
				\item{ odległości $o:  L \times L \rightarrow \mathbb{R} $}
				\item{ przepływów $p: W \times W \rightarrow \mathbb{R} $}
			\end{itemize}}
	\end{itemize}
		Celem optymalizacji jest znalezienie takiej funkcji $ f: L \rightarrow W $  przydziału elementów z $L$ do elementów z $W$ , która minimalizuje funkcję:
	$$\sum_{a,b \in L}o(a,b)\times p(f(a),f(b))$$
	\emph{QAP} może modelować następującą sytuację: w pewnej firmie jest $n$ wydziałów, ich zbiór oznaczymy przez $W$ oraz $n$ lokalizacji (budynki, pomieszczenia, miasta), których zbiór oznaczony jest przez $L$. Znane są odległości między lokalizacjami (funkcja $o$) oraz natężenie (przepływ) ruchu pomiędzy wydziałami (funkcja $p$). Koszt ruchu między wydziałami to odległość pomiędzy lokalizacjami do których są one przypisane pomnożony przez natężenie ruchu między tymi wydziałami. Należy tak przyporządkować lokalizacje do wydziałów (definiując funkcję $f$), aby łączny koszt ruchu między wydziałami był jak najmniejszy.

	Zastosowania \emph{QAP}:
	\begin{itemize}
		\item{projektowanie układów elektronicznych}
		\item{rozmieszczanie fabryk, centrów dystrybucji itp.}
	\end{itemize}
	
	\emph{QAP} jest problemem \emph{NP-trudnym}, stąd do znalezienia rozwiązania stosuje się heurystyki. W dalszej części dokumentu przedstawiono porównanie algorytmów przeszukiwania lokalnego (\emph{Local Search}): \emph{Greedy},  \emph{Steepest}, \emph{Tabu Search} oraz~\emph{Simulated Annealing}. Jako punkt odniesienia do porównań służą algorytm losowy (\emph{Random Search}) i~prosta heurystyka. Wszystkie algorytmy zostały zaimplementowane w~języku Python 2.7 i~przetestowane na komputerze z~procesorem Intel~Core i5~2.4 GHz. Do obliczeń wykorzystano jeden rdzeń procesora.

	\subsection{Użyty operator sąsiedztwa\label{ss:operator}}
	Rozwiązanie jest reprezentowane przez permutację zbioru wydziałów -- umiejscowienie $m$-tego wydziału na $k$-tym miejscu permutacji przypisuje go do $k$-tej lokalizacji.
	Użyty operator sąsiedztwa to \emph{2-opt}, czyli sąsiednie rozwiązanie powstaje przez zamianę 2~elementów w~permutacji będącej reprezentacją rozwiązania.

	\subsection{Parametry algorytmów \emph{SA} i~\emph{TS}}
	Skuteczność działania algorytmów \emph{Simulated Annealing} oraz \emph{Tabu Search} w~dużej mierze zależy od doboru odpowiednich parametrów. Kryterium stopu dla obu tych algorytmów jest następujące: jeśli przez 10~ostatnich iteracji nie nastapiła poprawa, zatrzymaj (w~przypadku \emph{SA} jako jedną iterację rozumiemy w~tym kontekście przejście jednego ,,schodka'' temperatury). Pozostałe parametry specyficzne dla konkretnych metod opisane są poniżej.
		\subsubsection{Parametry \emph{SA}}
			\begin{itemize}
			\item{\textbf{Dekrementacja temperatury.} Nowa temperatura obliczana jest poprzez przemnożenie starej przez parametr $\alpha=0.9$.}
			\end{itemize}
		\subsubsection{Parametry \emph{TS}}
\section{Eksperymenty}
	\subsection{Porównanie działania algorytmów}
		\subsubsection{Czas działania}


			Na rysunku \ref{fig:time} pokazano porównanie czasu działania algorytmów dla różnych instancji \emph{QAP}. Ze względu na to, że różnica w czasach wykonywania algorytmu \emph{Random} i heurystyki jest niewielka względem różnicy, która dzieli je od czasów wykonywania algorytmów \emph{Local Search}, porównanie czasów działania dwóch pierwszych pokazano osobno na rysunku \ref{fig:time_hr} używając dokładniejszej skali.


			Łatwo zauważyć, że \emph{Greedy} sprawuje się lepiej od~\emph{Steepest} dla wszystkich badanych instancji, jeśli chodzi o czas działania. Wynika to ze sposobu, w~który badane jest sąsiedztwo w~tych dwóch wersjach \emph{przeszukiwania lokalnego} -- \emph{Greedy} przeszukuje je do momentu znalezienia rozwiązania lepszego niż obecne, natomiast \emph{Steepest} przeszukuje całe. Teoretycznie algorytm \emph{Steepest} może zbiegać szybciej do optimum lokalnego, co dawałoby mu przewagę nad \emph{Greedy}, jednak w~naszym eksperymencie efekt ten nie został zaobserwowany.


			Czasy wykonywania dla \emph{Random} oraz \emph{Heuristic} nie wymagają większego komentarza -- algorytm losowy jest szybszy niż heurystyka, gdyż wymaga jedynie wygenerowania losowej permutacji, podczas gdy heurystyka musi również zbadać funkcje odległości i~przepływu.


			Na podstawie obserwacji czasu działania algorytmów \emph{przeszukiwania lokalnego}, można wysnuć wnioski o charakterze badanych instancji. Nie jest zaskoczeniem, że wraz z~ich rozmiarem rośnie czas wykonywania algorytmów; warto jednak zaobserwować, że w~przypadku instancji \emph{tai40b} czas wykonywania jest dwa razy większy niż dla instancji \emph{lipa40a}, mającej przecież ten sam rozmiar. Ponieważ rozmiar przeszukiwanego sąsiedztwa jest ten sam, powodem musi być zbieżność do optimów lokalnych -- prawdopodobnie są one nieliczne, bądź też hiperpłaszczyzna problemu ma wiele obszarów płaskich, po których algorytmy krążą w~poszukiwaniu spadku.

			\begin{figure}[h]
				\includegraphics[scale=0.90]{../results/time}
				\caption{Porównanie czasu działania algorytmów dla różnych instancji \emph{QAP}\label{fig:time}}
			\end{figure}
			
			\begin{figure}[h]
				\includegraphics[scale=0.90]{../results/time_hr}
				\caption{Porównanie czasu działania algorytmu \emph{Random} i heurystyki dla różnych instancji \emph{QAP}\label{fig:time_hr}}
			\end{figure}

		\subsubsection{Średnia jakość rozwiązania\label{ss:meanquality}}
Jakość rozwiązania jest wyrażona przez stosunek wartości funkcji celu dla rozwiązania optymalnego (znanego apriori) do wartości funkcji celu dla danego rozwiązania. Najwyższa możliwa jakość, jaką może osiągnąć rozwiązanie to $100\%$. Im wyższa wartość osiąganej przez rozwiązanie funkcji celu, tym niższa jakość rozwiązania. Wraz z pogarszaniem się rozwiązań będzie ona malała asymptotycznie do zera (ze względu na skończoną precyzję reprezentacji liczb rzeczywistych w~pamięci komputera najgorsze rozwiązania mogą mieć jakość równą 0).


			Na podstawie wykresu \ref{fig:quality} można wydzielić dwie grupy algorytmów ze względu na~średnią jakość rozwiązania: \emph{Greedy} i~\emph{Steepest} oraz \emph{Random} i~\emph{Heuristic}. Pierwsza z~grup radzi sobie zdecydowanie lepiej, wyniki dla obu algorytmów są niemal identyczne -- minimalna przewaga któregoś z~nich zależy wyłącznie od instancji. Najgorzej, co nie jest zaskoczeniem, radzi sobie algorytm losowy. Prosta heurystyka radzi sobie tylko odrobinę lepiej, chociaż dla niektórych instancji (tutaj dla \emph{esc16a}) daje zaskakująco dobre rezultaty, zbliżone jakościowo do tych uzyskiwanych za pomocą algorytmów \emph{przeszukiwania lokalnego}.


			\begin{figure}[h]
				\includegraphics[scale=0.90]{../results/quality}
				\caption{Porównanie średniej jakości rozwiązań generowanych przez algorytmy dla różnych instancji \emph{QAP}\label{fig:quality}}
			\end{figure}

		\subsubsection{Jakość najlepszego rozwiązania}

			Porównanie wyników jakości najlepszego rozwiązania (rysunek \ref{fig:best_quality}) z~wynikami średniej jakości rozwiązań (sekcja \ref{ss:meanquality}) dla danych instancji i~algorytmów pozwala nam powiedzieć coś o~determiniźmie uzyskiwanych rezultatów. Wszystkie algorytmy poza \emph{Heuristic} są~niedeterministyczne, co wynika z~losowego wyboru punktu startowego, jednak niektóre charakteryzują się większym rozrzutem uzyskiwanych wyników. Na podstawie wartości odchylenia standardowego przedstawionych na wykresie \ref{fig:quality} oraz informacji o~najlepszych znalezionych rozwiązaniach można powiedzieć, że najbardziej losowy jest algorytm \emph{Random} (co nie jest zaskoczeniem), natomiast dla \emph{Greedy} i~\emph{Steepest} istnieje duża zbieżność do rozwiązania o~określonej jakości (przy czym jest ona zdecydowanie większa dla algorytmu \emph{Steepest}, co można zauważyć na podstawie wyników dla instancji \emph{chr12a}).


			Wracając zaś do~samej jakości najlepszych odnalezionych rozwiązań, zdecydowanie najlepiej radzi sobie \emph{Greedy}, dając lepsze rezultaty od pozostałych algorytmów dla wszystkich badanych instancji i~znajdując rezultaty bardzo bliskie optimum.

		 	\begin{figure}[h]
				\includegraphics[scale=0.90]{../results/best_quality}
				\caption{Porównanie jakości najlepszych rozwiązań generowanych przez algorytmy dla różnych instancji \emph{QAP}\label{fig:best_quality}}
			\end{figure}

		\subsubsection{Efektywność}

			Na rysunku \ref{fig:effectivenes} pokazano porównanie średniej efektywności algorytmów dla danych instancji \emph{QAP}, rozumianej jako iloraz średniej jakości uzyskiwanych rozwiązań oraz średniego czasu wywołania danego algorytmu. Na wykresie nie pokazano algorytmu \emph{Random}, ponieważ jego~czas wykonania jest bardzo mały, przez co umieszczenie go na wykresie z~pozostałymi algorytmami nie doprowadziłoby do żadnych ciekawych wniosków. Został on porównany osobno z~algorytmem \emph{Heuristic}, na rysunku~\ref{fig:effectivenes_fast}.



			\begin{figure}[h]
				\includegraphics[scale=0.90]{../results/effectivenes}
				\caption{Porównanie średniej efektywności (jakość/czas) algorytmów dla różnych instancji \emph{QAP}\label{fig:effectivenes}}
			\end{figure}

			\begin{figure}[h]
				\includegraphics[scale=0.90]{../results/effectivenes_fast}
				\caption{Porównanie średniej efektywności (jakość/czas) algorytmów dla różnych instancji \emph{QAP}\label{fig:effectivenes_fast}}
			\end{figure}


	\subsection{Szczegółowa analiza algorytmu GS}

		\subsubsection{Jakość rozwiązania początkowego vs jakość rozwiązania końcowego}
			Na rysunkach \ref{fig:gs.nug24}, \ref{fig:gs.chr12a} i~\ref{fig:gs.esc16a} widać zależność między rozwiązaniem początkowym a~końcowym dla wybranych instancji.
			
			Dla większości instancji wykresy te były podobne do rys.~\ref{fig:gs.nug24} (przybliżenie na rys.~\ref{fig:gs.nug24_zoom}). Świadczy to o tym, że w~tych instancjach optima lokalne nie były dużo gorsze od optimum globalnego, pozwalając na znalezienie dobrego rozwiązania w~każdym przebiegu. Ciekawsze są rysunki \ref{fig:gs.chr12a} i~\ref{fig:gs.esc16a} -- w~instancji \emph{chr12a} jakość rozwiązań początkowych była zdecydowanie niższa, nie przekraczając 40\%. Nie zawsze też znalezione rozwiązanie było bliskie optimum, w~większości przypadków algorytm kończył pracę w~punktach o~ocenie między 40\% a~95\%. Świadczy to o~tym, że w~krajobrazie tej instancji istnieje wiele optimów lokalnych, często zdecydowanie gorszych od optimum globalnego. Z~kolei w~instancji \emph{esc16a} rozwiązania początkowe były dość dobrej jakości -- między 50\% a~80\% -- zbieżność do optimum również była o~wiele lepsza, żadne z~rozwiązań końcowych nie miało oceny gorszej niż 80\%, często również udawało się znaleźć optimum globalne. Z~rozmieszczenia punktów można też wnioskować, że istnieje pięć różnych (pod względem oceny) optimów lokalnych, świadczy o~tym wrażenie umiejscowienia punktów danych ,,na siatce".
			
			\begin{figure}[h]
				\includegraphics[scale=0.90]{../results/gs_comparision_nug24.pdf}
				\caption{Zależność między rozwiązaniem startowym a~końcowym -- instancja \emph{nug24}\label{fig:gs.nug24}}				
			\end{figure}
			
			\begin{figure}[h]
				\includegraphics[scale=0.90]{../results/gs_comparision_nug24_zoom.pdf}
				\caption{Zależność między rozwiązaniem startowym a~końcowym -- instancja \emph{nug24}\label{fig:gs.nug24_zoom}, przybliżenie}				
			\end{figure}
			
			\begin{figure}[h]
				\includegraphics[scale=0.90]{../results/gs_comparision_chr12a.pdf}
				\caption{Zależność między rozwiązaniem startowym a~końcowym -- instancja \emph{chr12a}\label{fig:gs.chr12a}}				
			\end{figure}
			
			\begin{figure}[h]
				\includegraphics[scale=0.90]{../results/gs_comparision_esc16a.pdf}
				\caption{Zależność między rozwiązaniem startowym a~końcowym -- instancja \emph{esc16a}\label{fig:gs.esc16a}}				
			\end{figure}
		
		\subsubsection{Wpływ liczby restartów na jakość rozwiązania}		
			W przypadku większości testowanych instancji nie zauważono żadnego wpływu ilości restartów multi-random na jakość najlepszego znalezionego do danego momentu rozwiązania. Działo się tak dlatego, że w większości przypadków algorytmy już za pierwszym razem osiągały jakość  100\%  lub bardzo zbliżoną. Tak było np. w przypadku instancji \emph{bur26a}, co pokazano na rys.~\ref{fig:mr.bur26a}. W przypadku niektórych instancji pierwsze rozwiązania były bardzo dobre (o jakości ok 90\%) i wraz z następnymi uruchomieniami ich jakość rosła. Tylko dla instancji \emph{chra12a} zauważono znaczącą (większą niż 5\%) poprawę wraz z kolejnymi uruchomieniami, co pokazano na rys.~\ref{fig:mr.chr12a}. Pierwsze rozwiązanie dla tej instancji miało jakość ok 70\%, co umożliwiło poprawę rozwiązania o ok 30\% aż do poziomu 100\%. Różnice te wynikają z odmiennego krajobrazu rozwiązań dla tych instancji: jak widać na rys.~\ref{fig:mr.chr12a} jakość rozwiązania różni się znacznie w zależności od uruchomienia, czyli w zależności od punktu w którym algorytm zaczyna działać. Świadczy to o tym, że w krajobrazie rozwiązań jest dużo optimów lokalnych gorszych od optimum globalnego, w których algorytm ,,utyka". W przypadku pozostałych instancji krajobraz musi być bardziej ,,gładki" lub ,,wyższy". W pierwszym przypadku algorytm niezależnie od pkt.~startowego znajduje optimum globalne -- stąd brak różnic w kolejnych uruchomieniach -- tak jest w przypadku instancji \emph{bur26a} co widać na rys.~\ref{fig:mr.bur26a}. W drugim wszystkie możliwe rozwiązania są blisko rozwiązania optymalnego i stąd poprawa jakości jest na tyle mała, że patrząc na wykresy wydaje się nieistotna -- tak jest w przypadku instancji \emph{kra30a} co widać na rys \ref{fig:mr.kra30a}.
			\\Ciężko jednoznacznie określić kiedy przerwać ponowne uruchamianie algorytmu. Można kierowaź się jednym lub kilkoma z poniższych warunków:
			\begin{itemize}
				\item{odchylenie standardowe jakości rozwiązań jest mniejsze niż określony próg}
				\item{odległość najlepszego rozwiązania od optimum nie jest za mała}
				\item{tempo poprawy najlepszej jakości spada poniżej określonego progu}
				\item{całościowy czas wykonywania algorytmu przekracza wyznaczony próg}
				\item{algorytm osiąga pożądaną jakość}
				\item{Po wykonywaniu algorytmu przez pewien czas koszt jego wykonywania przekracza zyski z poprawy jakości (jeśli można je mierzyć tą samą miarą)}
			\end{itemize}
			\begin{figure}[h]
				\includegraphics[scale=0.90]{../results/multirandom_kra30a.pdf}
				\caption{Zależność jakości średniego i najlepszego ze znalezionych dotychczas rozwiązań od liczby restartów w multi-random -- instancja \emph{kra30a}\label{fig:mr.kra30a}}		
			\end{figure}
			\begin{figure}[h]
				\includegraphics[scale=0.90]{../results/multirandom_bur26a.pdf}
				\caption{Zależność jakości średniego i najlepszego ze znalezionych dotychczas rozwiązań od liczby restartów w multi-random -- instancja \emph{bur26a}\label{fig:mr.bur26a}}		
			\end{figure}
			\begin{figure}[h]
				\includegraphics[scale=0.90]{../results/multirandom_chr12a.pdf}
				\caption{Zależność jakości średniego i najlepszego ze znalezionych dotychczas rozwiązań od liczby restartów w multi-random -- instancja \emph{chr12a}\label{fig:mr.chr12a}}		
			\end{figure}

	\subsection{Ocena podobieństwa rozwiązań}
		W celu oceny podobieństwa rozwiązań zaimplementowano dwie miary podobieństwa rozwiązań problemu \emph{QAP}. Obie z nich operują na permutacji zbioru wydziałów jako reprezentacji rozwiązania problemu (została opisana w pkt.~\ref{ss:operator}). Pierwszą z nich nazwano ,,podobieństwem binarnym" -- jest to stosunek liczby zgodnych pozycji w dwóch porównywanych permutacjach do liczy wszystkich elementów permutacji. Miara ta przyjmuje wartości z zakresu $[0,1]$, przy czym wartość 0 osiąga dla rozwiązań, które nie przypisują żadnego ,,wydziału" do tej samej ,,lokalizacji".
	\\Druga miara, którą nazwano ,,podobieństwo cząstkowe", w przypadku gdy odpowiadające sobie elementy permutacji nie są identyczne, porównuje ich wkład do oceny rozwiązania. Motywację tego zabiegu przedstawimy na przykładzie sytuacji ,,lokalizacje i wydziały": jeśli dwie lokalizacje leżą koło siebie, czyli znajdują się tak samo daleko od pozostałych lokalizacji, to nie ma różnicy do której z nich przypiszemy wydział A a do drugiej wydział B (w~rzeczywistości różnica może wystąpić, ponieważ odległość między tymi dwiema lokalizacjami może być niesymetryczna albo nawet ,,odległość" lokalizacji od samej siebie -- która nie w każdej instancji jest zerowa -- może być różna). W związku z tym, aby porównać dwie lokalizacje miara porównuje odpowiednie wiersze i~kolumny w~macierzy odległości wg poniższego wzoru:
		$$ sim(a, b) = \left(\sum_{i=1}^{N}\frac{min(d(a,i), d(b,i))}{max(d(a,i), d(b,i))} +  \sum_{i=1}^{N}\frac{min(d(i,a), d(i,b))}{max(d(i,a), d(i,b))}\right) \div 2N  $$
		gdzie $a$ i $b$ to lokalizacje, $d(x,y)$ to odległość między lokalizacjami $x$ i $y$, $N$ to liczba lokalizacji. Jeśli licznik któregoś z iloczynów występujących wewnątrz powyższego wzoru jest równy 0, to przyjmuje się, że cały iloczyn ma wartość zero (nawet jeśli w mianowniku też jest zero) aby uniknąć dzielenia przez 0.
\\Ostatecznie podobieństwo między dwoma rozwiązaniami mierzone miarą ,,podobieństwa cząstkowego" wyraża się wzorem:
$$ SolutionSim(s1, s2) = \frac{\sum_{i=0}^{N}{sim(s1[i], s2[i])}}{N}$$	
		gdzie $s[i]$ to $i$-ty element rozwiązania $s$, $sim(a,b)$ to miara podobieństwa lokalizacji opisana powyżej.
		Miara ta tak samo jak miara podobieństwa binarnego przyjmuje wartości z zakresu $ [0,1] $ .
	\\Na rys \ref{fig:bin_sim} i \ref{fig:part_sim} przedstawiono średnie podobieństwo między wszystkimi parami wygenerowanych rozwiązań lokalnych. 
%	Jak widać, dla wszystkich instancji i obu miar podobieństwa algorytm \emph{Steepest} generował bardziej podobne do siebie rozwiązania. Jeśli dwa różne rozwiązania mają wspólne sąsiednie rozwiązanie i dla obu z nich jest ono najlepszym z ich sąsiednich rozwiązań, to algorytm \emph{Steepest} wybierze dla obu dotychczasowych rozwiązań właśnie tego sąsiada jako następne rozwiązanie. Nie musi tak być w przypadku algorytmu \emph{greedy}, stąd w steepset rozwiązania mogą bardziej zbiegać się w tym samym kierunku przez co ostateczne rozwiązania są bardziej do siebie podobne.
	\\Co zrozumiałe, w przypadku algorytmu random rozwiązania są najmniej do siebie podobne, jednak widać, że różnica względem \emph{Steepest} i \emph{Greedy} nie jest znaczna. Widać dzięki temu, że podobieństwo rozwiązań znajdowanych przez te algorytmy jest w dużej mierze dziełem przypadku. W najlepszym przypadku różnica między średnim podobieństwem rozwiązań algorytmu \emph{Random} i \emph{Steepest} wynosi ok $0.1$.
			\begin{figure}[h]
				\includegraphics[scale=0.90]{../results/binary_similarity.pdf}
				\caption{Średnie podobieństwo binarne między wszystkimi parami wygenerowanych rozwiązań lokalnie optymalnych dla algorytmów \emph{Greedy} i \emph{Steepest}\label{fig:bin_sim}}		
			\end{figure}				
			\begin{figure}[h]
				\includegraphics[scale=0.90]{../results/partial_similarity.pdf}
				\caption{Średnie podobieństwo cząstkowe między wszystkimi parami wygenerowanych rozwiązań lokalnie optymalnych dla algorytmów \emph{Greedy} i \emph{Steepest}\label{fig:part_sim}}		
			\end{figure}	
		
\section{Podsumowanie}
	\subsection{Wnioski}
		\begin{itemize}
			\item Jakość rozwiązań osiągana przez \emph{Greedy} i~\emph{Steepest} jest porównywalna, stąd lepiej stosować \emph{Greedy} ze względu na krótszy czas pojedynczego wywołania algorytmu.
			\item Zaproponowana heurystyka daje efekty porównywalne z~algorytmem\emph{Random}.
			\item O~ile \emph{Local Search} sprawdza się dla wszystkich instancji, efektywność 	\emph{Random} zależy od konkretnego przypadku.
			\item W~żadnym przypadku nie znaleziono związku między jakością rozwiązania startowego a~końcowego.
			\item Podobieństwo cząstkowe rozwiązań znajdowanych przez dany algorytm na danej instancji jest podobne dla różnych algorytmów.
		\end{itemize}


%%%%%%%%%%%%%%%% literatura %%%%%%%%%%%%%%%%

\bibliography{sprawozdanie}
\bibliographystyle{plain}

\end{document}

